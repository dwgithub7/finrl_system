
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import json
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight

# ‚úÖ ÏÑ§Ï†ï
INPUT_PATH = "data/processed/SOLUSDT_1m_with_trend.csv"
OUTPUT_X_PATH = "data/dataset/SOLUSDT_X_lstm.npy"
OUTPUT_Y_PATH = "data/dataset/SOLUSDT_y_lstm.npy"
OUTPUT_META_PATH = "data/dataset/SOLUSDT_meta.json"
TASK_TYPE = "classification"
WINDOW_SIZE = 60
HORIZON = 1
THRESHOLD = 0.001  # Ï¥àÍ∏∞Í∞í

def classify_return(x, threshold):
    if x > threshold:
        return 1
    elif x < -threshold:
        return -1
    else:
        return 0

def rebalance_dataset(X, y, method="both"):
    from collections import Counter
    from imblearn.over_sampling import RandomOverSampler
    from imblearn.under_sampling import RandomUnderSampler

    print("‚öñÔ∏è ÌÅ¥ÎûòÏä§ Ïû¨Ï°∞Ï†ï Ï†Ñ:", dict(Counter(y)))
    X_flat = X.reshape((X.shape[0], -1))

    if method == "under":
        rus = RandomUnderSampler()
        X_res, y_res = rus.fit_resample(X_flat, y)
    elif method == "over":
        ros = RandomOverSampler()
        X_res, y_res = ros.fit_resample(X_flat, y)
    elif method == "both":
        rus = RandomUnderSampler()
        ros = RandomOverSampler()
        X_temp, y_temp = rus.fit_resample(X_flat, y)
        X_res, y_res = ros.fit_resample(X_temp, y_temp)
    else:
        return X, y

    X_res = X_res.reshape((-1, X.shape[1], X.shape[2]))
    print("‚öñÔ∏è ÌÅ¥ÎûòÏä§ Ïû¨Ï°∞Ï†ï ÌõÑ:", dict(Counter(y_res)))
    return X_res, y_res

def make_lstm_dataset(input_csv=INPUT_PATH, window_size=WINDOW_SIZE, horizon=HORIZON,
                      threshold=THRESHOLD, task=TASK_TYPE):

    df = pd.read_csv(input_csv, index_col=0, parse_dates=True)
    df["future_return"] = df["log_return"].shift(-horizon)
    df = df[df["future_return"].abs() > 1e-5]
    df.dropna(inplace=True)

    # 1Ô∏è‚É£ Í¥ÄÎßù ÎπÑÏú® Î≥¥Ï†ï (threshold Ï°∞Ï†ï)
    def adjust_threshold(df, init_threshold):
        t = init_threshold
        while True:
            y_temp = df["future_return"].apply(lambda x: classify_return(x, t))
            counts = y_temp.value_counts(normalize=True)
            if counts.get(0, 0) < 0.05:
                t *= 0.8  # Îçî ÎØºÍ∞êÌïòÍ≤å
            else:
                break
            if t < 0.0001:
                break
        return t

    adjusted_threshold = adjust_threshold(df, threshold)
    print(f"‚öôÔ∏è ÏÇ¨Ïö©Îêú threshold: {adjusted_threshold:.6f}")
    df["target"] = df["future_return"].apply(lambda x: classify_return(x, adjusted_threshold))

    # ÌîºÏ≤ò ÏûêÎèô Ïù∏Ïãù
    exclude_cols = ["future_return", "target"]
    feature_cols = [col for col in df.columns if col not in exclude_cols]

    # ÏúàÎèÑÏö∞ Í∏∞Î∞ò ÏãúÍ≥ÑÏó¥ ÏÉùÏÑ±
    X, y = [], []
    for i in range(window_size, len(df) - horizon):
        X.append(df.iloc[i - window_size:i][feature_cols].values)
        y.append(df.iloc[i]["target"])

    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.int64)

    # 2Ô∏è‚É£ + 3Ô∏è‚É£ Ïñ∏ÎçîÏÉòÌîåÎßÅ + Ïò§Î≤ÑÏÉòÌîåÎßÅ Î≥ëÌñâ
    X, y = rebalance_dataset(X, y, method="both")

    print(f"‚úÖ Ïû¨Ï°∞Ï†ï ÌõÑ: X.shape = {X.shape}, y.shape = {y.shape}")

    # ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò
    class_weights = compute_class_weight("balanced", classes=np.unique(y), y=y)
    print("üìå ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò:", dict(zip(np.unique(y), class_weights.tolist())))

    # ÏãúÍ∞ÅÌôî
    unique, counts = np.unique(y, return_counts=True)
    plt.bar(unique, counts)
    plt.title("Target Class Distribution (Rebalanced)")
    plt.xlabel("Class")
    plt.ylabel("Count")
    plt.grid(True)
    plt.show()

    # Ï†ÄÏû•
    os.makedirs(os.path.dirname(OUTPUT_X_PATH), exist_ok=True)
    np.save(OUTPUT_X_PATH, X)
    np.save(OUTPUT_Y_PATH, y)

    meta = {
        "threshold": adjusted_threshold,
        "feature_cols": feature_cols,
        "X_shape": X.shape,
        "y_shape": y.shape,
        "class_weights": class_weights.tolist()
    }
    with open(OUTPUT_META_PATH, "w", encoding="utf-8") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)

    print("üíæ Ï†ÄÏû• ÏôÑÎ£å:", OUTPUT_X_PATH, OUTPUT_Y_PATH, OUTPUT_META_PATH)
    return X, y

# ‚úÖ Ïã§Ìñâ
if __name__ == "__main__":
    make_lstm_dataset()
